<!DOCTYPE html>

<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <!-- Removed preload for faster initial render on slow connections -->
<link rel="stylesheet" type="text/css" href="./src1/stylesheet.css">
<noscript><link rel="stylesheet" type="text/css" href="./src1/stylesheet.css"></noscript>


<style>
#dmimage {
transition: transform 0.5s;
}
#dmimage:hover {
transform: scale(1.2);
}

#figimage {
transition: transform 0.5s;
}
#figimage:hover {
transform: scale(1.1);
}


body { padding : 20px 0; font-size : 20px; background-image : url("bg.png");} 

.img-circle {
    border-radius: 50%;
}

.shadow {box-shadow: rgba(0, 0, 0, 0.15) 6.00px 6.00px 2.6px;}
.shadow2  {box-shadow: rgba(0, 0, 0, 0.16) 0px 3px 6px, rgba(0, 0, 0, 0.23) 0px 3px 6px;}
.leftSideBar{display:none !important;}
.rightSideBar{display:none !important;}

.site-footer {

  text-align: center;
  margin: 0px 0;
  padding: 0px 0;
}

#social-wrapper {
  text-align: center;
}

/*Social Media src2/icons*/
.social-wrapper {
  text-align: center;
}

.social-wrapper ul li {
  display: inline;
  margin: 0 5px;
}

.twitter-icon,
.facebook-icon,
.instagram-icon,
.linkedin-icon,
.googleplus-icon,
.youtube-icon,
.foursquare-icon{
  margin-top: .625em;
  width: 20px;
  height: 20px;
  opacity: .6;
  filter: alpha(opacity=60); /* For IE8 and earlier */
  border-radius: 25px;
}

.twitter-icon:hover,
.facebook-icon:hover,
.instagram-icon:hover,
.linkedin-icon:hover,
.googleplus-icon:hover,
.youtube-icon:hover,
.foursquare-icon:hover {
  opacity: 1.0;
  filter: alpha(opacity=100); /* For IE8 and earlier */
}

.footer-nav p {
  text-align: center;
}

.column {
  float: left;
  padding: 5px;
}

.left {
  width: 34%;

}

.right {
  width: 66%;

}

/* Clear floats after the columns */
.row:after {
  content: "";
  display: table;
  clear: both;
}

/*@media screen and (max-width: 600px) {
  .column {
    width: 100%;
  }
}*/

.tabs {
  margin: 20px;
  padding: 0;
  list-style: none;
  position: relative;
  border-bottom: 1px solid #ccc;
}
.tabs .active-tab {
  border-top: 1px solid #ccc;
  border-left: 1px solid #ccc;
  border-right: 1px solid #ccc;
  border-bottom: none;
  position: relative;
  color: black;
}
.tabs .active-tab:after {
  width: 100%;
  height: 2px;
  position: absolute;
  content: "";
  bottom: -0.1em;
  left: 0;
  background: white;
}
.tabs li {
  display: inline-block;
  cursor: pointer;
  color: #3a5ea7;
  padding: 5px 10px;
}
.tabs li:first-child {
  margin-left: 10px;
}

.tabs-content {
  margin: 20px;
  padding: 0;
  list-style: none;
  max-height: 1400px; /* Default for mobile/tablet */
  overflow-y: scroll;
}
@media (min-width: 1000px) {
  .tabs-content {
    max-height: 1000px; /* For desktop */
  }
}
.tabs-content li {
  display: none;
}


.card-container {
    display: flex;
    flex-wrap: wrap;
    gap: 10px;
    justify-content: flex-start; /* Changed from center to flex-start for left alignment */
    padding: 10px;
}

.card {
    background-color: #fff;
    border-radius: 10px;
    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
    max-width: 48%;
    padding: 10px;
    transition: transform 0.3s ease-in-out, box-shadow 0.3s ease-in-out;
  
}

.card h2 {
    margin-top: 0;
}

.card p {
    color: #555;
}

.card:hover {
    transform: scale(1.1); /* Enlarge to 1.3x */
    box-shadow: 0 12px 16px rgba(0, 0, 0, 0.2);
    z-index: 10; /* Bring to front */
    position: relative; /* Needed for z-index to work */
}
* {box-sizing: border-box}
body {font-family: Verdana, sans-serif; margin:0}
.mySlides {display: none}
img {vertical-align: middle;}

/* Slideshow container */
.slideshow-container {
  max-width: 1000px;
  position: relative;
  margin: auto;
}

.research-heading {
  font-size: 1.3em; /* Larger font */
  font-weight: normal; /* No bold */
  color: #333; /* A slightly darker color for better style */
  margin-top: 20px;
  margin-bottom: 15px;
  padding-left: 10px; /* Align with card-container padding */
}

.conference-highlight {
  color: indianred;
  font-weight: bold;
}

hr {
  border: 0;
  height: 1px;
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.2), rgba(0, 0, 0, 0));
}

</style>



<!-- Please Remove the below lines if you are using my code-->
<!-- Google Analytics -->
<script src="./Ankan Bhunia - Homepage_files/track.php" async=""></script><script async="" src="./Ankan Bhunia - Homepage_files/analytics.js.download"></script><script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-143450446-1', 'auto');
ga('send', 'pageview');
</script>
<!-- End Google Analytics -->
<script type="text/javascript">(function(){var hstc=document.createElement('script'); hstc.src='https://log.hitsteps.com/track.php?code=422b10447cdcc581710fb4fc8399b0ba';hstc.async=true;var htssc = document.getElementsByTagName('script')[0];htssc.parentNode.insertBefore(hstc, htssc);})();
</script><noscript><a href="http://www.hitsteps.com/"><img src="//log.hitsteps.com/track.php?mode=img&amp;code=422b10447cdcc581710fb4fc8399b0ba" alt="web statistics" width="1" height="1" />web statistics</a></noscript>	
<script async src="//static.getclicky.com/101263529.js"></script>
<script async="" src="./Ankan Bhunia - Homepage_files/js"></script>
<!-- Please Remove the below lines if you are using my code#-->


  <script async="" src="./src1/js"></script>



  <title>Ankan Bhunia - Homepage</title>
  
  <meta name="author" content="Jon Barron">
 <!-- <meta name="viewport" content="width=device-width, initial-scale=1" /> -->
<meta name="viewport" content="width=700">

  
 <link rel = "icon" type = "image/png" href = "./src2/ju.png">
</head>



<body  data-new-gr-c-s-check-loaded="14.1023.0" data-gr-ext-installed="">
  <div style="font-family:Courier; ">
  <table style="width:100%;max-width:950px;border:0px;border-spacing:0px;background-color : #fff;box-shadow: 0px 0px 10px #999;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
			
			 <div id="container">
			  <div class="column left">
			<table border="0" cellpadding="0" cellspacing="4">

			  <tbody style="text-align:center"><tr><td valign="top" rowspan="6"><img id="dmimage" height="100" border="0" class="img-circle" src="im1.png" onmouseover="changeImage()" onmouseout="restoreImage()">
			</tbody>
			  <td style="text-align:center" valign="top" colspan="1"><h2 style="font-weight: normal; font-size: 1.5em;">Ankan Bhunia<br></h2>


          <p style="font-size: 13px; margin-top: -14px">ankan.bhunia [at] ed.ac.uk</p>

			    <p style="text-align:center">

                <!-- <a href="mailto:ankankumarbhunia@gmail.com">Email</a> &nbsp;/&nbsp; -->
                <a href="https://ankanbhunia.github.io/resume/Ankan_Resume.pdf">Resume</a> &nbsp;/&nbsp;
                <a href="https://scholar.google.com/citations?user=2leAc3AAAAAJ&amp;hl=en">Google Scholar</a> &nbsp;/&nbsp;
                <a href="https://github.com/ankanbhunia">GitHub</a>&nbsp;/&nbsp;
                <a href="https://www.linkedin.com/in/ankan-kumar-bhunia/">Linkedin</a>
              </p></td>
        </table>

      
    <h2>Recent News</h2>
	 <b>[09/2025]</b>: 1 paper at <a href="https://neurips.cc/">NeurIPS 2025</a><br>
    <b>[02/2025]</b>: 1 paper at <a href="https://cvpr.thecvf.com/">CVPR 2025</a><br>
      <!-- <b>[10/2024]</b>: 1 US patent granted <a href="https://patents.google.com/patent/US20240161360A1/en">(link)</a><br> -->
    <b>[02/2024]</b>: 1 paper at <a href="https://cvpr.thecvf.com/">CVPR 2024</a><br>
    <!-- <b>[10/2023]</b>: 1 US patent granted <a href="https://patents.google.com/patent/US11756244B1/en/">(link)</a><br> -->
     <b>[07/2023]</b>: 1 paper at <a href="https://iccv2023.thecvf.com/">ICCV 2023</a><br>
    <b>[06/2023]</b>: 1 paper at <a href="https://conferences.miccai.org/2023/en/">MICCAI 2023</a><br>
    <b>[02/2023]</b>: 1 paper at <a href="http://cvpr2023.thecvf.com/">CVPR 2023</a><br>
	<b>[07/2022]</b>: 1 paper at <a href="https://eccv2022.ecva.net/">ECCV 2022</a><br>
	<b>[07/2021]</b>: 1 paper at <a href="http://iccv2021.thecvf.com/home">ICCV 2021</a><br>
	<b>[10/2019]</b>: 1 paper at <a href="https://www.journals.elsevier.com/information-fusion">Information Fusion</a><br>
    <b>[07/2019]</b>: 1 paper at <a href="https://www.journals.elsevier.com/pattern-recognition">Pattern Recognition</a><br>
    <b>[03/2019]</b>: 1 paper at <a href="http://cvpr2019.thecvf.com//">CVPR 2019</a><br>
	<b>[05/2019]</b>: 1 paper at <a href="http://2019.ieeeicip.org/">ICIP 2019</a><br>
    <!-- <b>[05/2019]</b>: 1 paper at <a href="https://link.springer.com/journal/521">Neural Computing and Application</a><br> 
	<b>[08/2018]</b>: 1 paper at <a href="https://www.journals.elsevier.com/pattern-recognition">Pattern Recognition</a><br>
    <b>[04/2018]</b>: 3 papers at <a href="http://www.icpr2018.org/">ICPR 2018</a><br> -->

	  
<p></p>
    <h2 style="display:inline;">Education</h2>
    <!--<div style="top:-10px; position:relative;">-->

    <p></p>
  
    <table border="0" cellpadding="0" cellspacing="4">

    <tbody><tr><td valign="middle" rowspan="6"><img height="60" border="0", src="./src2/uoe.png">

    </td></tr><tr><td></td><td></td><td></td><td></td><td></td><td valign="top" colspan="2"><span class="h1"><b>University of Edinburgh, UK</b></span>
  
    <br><em>PhD at School of Informatics</em><br> 
          May 2023 - Present
  </td></tr></tbody></table>
     
	<p></p>
	
  	<table border="0" cellpadding="0" cellspacing="4">

	  <tbody><tr><td valign="middle" rowspan="6"><img height="60" border="0", src="./src2/ju.png">

	  </td></tr><tr><td></td><td></td><td></td><td></td><td></td><td valign="top" colspan="2"><span class="h1"><b>Jadavpur University, India</b></span>
	
	  <br><em>B.E. in Electrical Engineering</em><br> 
          July 2016 - May 2020
	</td></tr></tbody></table>

		
		
<p></p>
    <h2 style="display:inline;">Research Experiences</h2>
		<p></p>
	
  	 <table border="0" cellpadding="0" cellspacing="4">

	  <tbody><tr><td valign="middle" rowspan="6"><img height="60" border="0" src="./src2/mbzuai.png">

	  </td></tr><tr><td></td><td></td><td></td><td></td><td></td><td valign="top" colspan="2"><span class="h1"><b>MBZUAI, Abu Dhabi</b></span>
	
	  <br><em>Researcher, Intelligent Visual Analytics Lab</em>.<br> 
	  Nov 2020 - Apr 2023 </a>
	  
	</td></tr></tbody></table>
	
	<p></p>
	
  	<table border="0" cellpadding="0" cellspacing="4">

	  <tbody><tr><td valign="middle" rowspan="6"><img height="60" border="0" src="./src2/UOM.png">

	  </td></tr><tr><td></td><td></td><td></td><td></td><td></td><td valign="top" colspan="2"><span class="h1"><b>University of Manitoba, Winnipeg, Canada</b></span>
	
	  <br><em>MITACS Internship</em>, 2019.<br> 
	  May 2019 - August 2019 </a>
	  
	</td></tr></tbody></table>
	<p></p>
	<table border="0" cellpadding="0" cellspacing="4">

	  <tbody><tr><td valign="middle" rowspan="6"><img height="60" border="0" src="./src2/bosch.jpg">

	  </td></tr><tr><td></td><td></td><td></td><td></td><td></td><td valign="top" colspan="2"><span class="h1"><b>Robert Bosch, Bangalore</b></span>
	
	  <br><em>Intern, Computer Vision Lab</em><br> 
	  June 2018 - July 2018 </tbody></table>
		<p></p>
	<!-- <table border="0" cellpadding="0" cellspacing="4">

	  <tbody><tr><td valign="middle" rowspan="6"><img height="60" border="0" src="./src2/iitr.png">

	  </td></tr><tr><td></td><td></td><td></td><td></td><td></td><td valign="top" colspan="2"><span class="h1"><b>IIT Roorkee, India</b></span>
	
	  <br><em>Under Prof. Partha Pratim Roy</em><br>
	  June 2017 - May 2020
	</td></tr></tbody></table> -->



</div>

<div class="column right" style="margin-left:-10px">


  
 
<!--   	  <h2>Research</h2>
	  <p>
		I am broadly interested in computer vision, machine learning, and AI. I mostly work on generative models and visual perception models from a small amount of data. 
	  </p> -->
    
<br>
      <p style="padding-left: 15px; padding-right: 0px; text-align: justify">
         
   <font style="color: black;"> I'm a 3rd year PhD student in the <a href="https://www.ed.ac.uk/informatics">School of Informatics</a> at the <a href="https://en.wikipedia.org/wiki/University_of_Edinburgh">University of Edinburgh</a>. I work with <a href=https://homepages.inf.ed.ac.uk/hbilen/>Dr. Hakan Bilen</a> in the <a href=https://groups.inf.ed.ac.uk/vico/>Visual Computing Group</a> (VICO) and <a href=https://enigma-li.github.io/>Dr. Changjian Li</a> from GraphVix lab. </font> 
	 <font style="color: black;"> Previously, I was a full-time research assistant at MBZUAI, Abu Dhabi, where I worked on computer vision and machine learning with <a href="https://sites.google.com/view/fahadkhans/home">Dr Fahad Shahbaz Khan</a>, <a href="https://salman-h-khan.github.io/">Dr Salman Khan</a> and <a href="https://scholar.google.com/citations?hl=en&user=bZ3YBRcAAAAJ&view_op=list_works&sortby=pubdate">Dr Hisham Cholakkal</a>. During my undergrad, I had worked with <a href="https://users.encs.concordia.ca/~wayang/">Dr Yang Wang</a> at the University of Manitoba, Canada and <a href="http://parimal.iitr.ac.in/people/partha-pratim-roy">Dr Partha Roy</a> at IIT Roorkee, India. I did my bachalors from <a href="https://en.wikipedia.org/wiki/Jadavpur_University">Jadavpur University</a>, Kolkata in Electrical Engineering.

    </p>

<ul class="tabs">
  <li class="active-tab" id="tab-publications">Publications</li>
  <li id="tab-research">Research</li>
  <li id="tab-patents">Patents</li>
  <!-- <li>CV/Resume</li> -->
  <li id="tab-contact">Contact</li>
</ul>

<ul class="tabs-content">
  <li id="content-publications">
<div>

  
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

             <div style="margin-left:15px;"> More details are available on <a href="https://scholar.google.com/citations?user=2leAc3AAAAAJ&hl=en">Google Scholar</a></div><br>


             <tr>
              <td style="width:200px;height:100px; margin-left:20px;margin-top:15px;">
                <img id="figimage" class=shadow src="./src2/iad.jpg" height="90", width="120" style="margin-left:10px;">
                <br>
                <br>
  
              </td>              
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="">
                  <papertitle>Interactive Anomaly Detection for Articulated Objects via Motion Anticipation</papertitle></a>
                - [<a href="https://groups.inf.ed.ac.uk/vico/research/interactiveAD/"><em style="color: #767872;">webpage</em></a>] / [<a href="https://openreview.net/pdf?id=t22zHB6yQ0"><em style="color: #767872;">paper</em></a>] / [<a href="https://openreview.net/forum?id=t22zHB6yQ0"><em style="color: #767872;">openreview</em></a>]
                <br>
                <strong>Ankan Bhunia</strong>, Changjian Li, Hakan Bilen,
                <br>
                <strong style="color: indianred;"><em>NeurIPS</em>, 2025</strong>  (Main Track)<br>
                <br>
                <!-- -->
            <tr>


             <tr>
            <td style="width:200px;height:100px; margin-left:20px;margin-top:15px;">
              <img id="figimage" class=shadow src="./src2/o3.jpg" height="90", width="120" style="margin-left:10px;">
              <br>
              <br>

            </td>              
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2406.20099">
                <papertitle>Odd-One-Out: Anomaly Detection by Comparing with Neighbors</papertitle></a>
              - [<a href="https://arxiv.org/abs/2406.20099"><em style="color: #767872;">paper</em></a>] / [<a href="https://github.com/VICO-UoE/OddOneOutAD"><em style="color: #767872;">code</em></a>] / [<a href="https://huggingface.co/datasets/ankankbhunia/odd-one-out"><em style="color: #767872;">dataset</em></a>]
              <br>
              <strong>Ankan Bhunia</strong>, Changjian Li, Hakan Bilen,
              <br>
              <strong style="color: indianred;"><em>CVPR</em>, 2025</strong><br>
              <br>
              <!-- -->
          <tr>


             <tr>
            <td style="width:200px;height:100px; margin-left:20px;margin-top:15px;">
              <img id="figimage" class=shadow src="./src2/looking3d.jpg" height="90", width="120" style="margin-left:10px;">

            </td>              
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Bhunia_Looking_3D_Anomaly_Detection_with_2D-3D_Alignment_CVPR_2024_paper.pdf">
                <papertitle>Looking 3D: Anomaly Detection with 2D-3D Alignment</papertitle>              </a>
              - [<a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Bhunia_Looking_3D_Anomaly_Detection_with_2D-3D_Alignment_CVPR_2024_paper.pdf"><em style="color: #767872;">paper</em></a>] / [<a href="https://huggingface.co/datasets/ankankbhunia/brokenchairs180k/tree/main"><em style="color: #767872;">dataset</em></a>] / [<a href="https://github.com/VICO-UoE/Looking3D"><em style="color: #767872;">code</em></a>] / [<a href="https://groups.inf.ed.ac.uk/vico/research/Looking3D/"><em style="color: #767872;">webpage</em></a>]
              <br>
              <strong>Ankan Bhunia</strong>, Changjian Li, Hakan Bilen,
              <br>
              <strong style="color: indianred;"><em>CVPR</em>, 2024</strong><br>
              <!-- -->
          <tr>


               <tr>
            <td style="width:200px;height:100px; margin-left:20px;margin-top:15px;">
              <img id="figimage" class=shadow src="./src2/gmnr.png" height="90", width="120" style="margin-left:10px;">

            </td>              
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2304.01172">
                <papertitle>Generative Multiplane Neural Radiance for 3D-Aware Image Generation</papertitle>              </a>
                 - [<a href="https://arxiv.org/abs/2304.01172"><em style="color: #767872;">paper</em></a>] / [<a href="https://github.com/VIROBO-15/GMNR"><em style="color: #767872;">code</em></a>] 
              <br>
              Amandeep Kumar,
              <strong>Ankan Bhunia</strong>, Sanath Narayan, Hisham Cholakkal,
              Rao Anwer,
              <aa href="https://salman-h-khan.github.io/">Salman Khan</a>, Ming-Hsuan Yang,
              <aa href="https://sites.google.com/view/fahadkhans/home">Fahad Khan</a>,
              <br>
              <strong style="color: indianred;"><em>ICCV</em>, 2023</strong><br>
              <!-- -->


          <tr>



            <td style="width:200px;height:100px; margin-left:20px;margin-top:15px;">
              <img id="figimage" class=shadow src="./src2/pidm.png" height="90", width="120" style="margin-left:10px;">

            </td>              
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2211.12500">
                <papertitle>Person Image Synthesis via Denoising Diffusion Model</papertitle>              </a>

             
                - [<a href="https://arxiv.org/abs/2211.12500"><em style="color: #767872;">paper</em></a>] / [<a href="https://github.com/ankanbhunia/PIDM"><em style="color: #767872;">code</em></a>] / [<a href="https://colab.research.google.com/github/ankanbhunia/PIDM/blob/main/PIDM_demo.ipynb"><em style="color: #767872;">demo</em></a>] / [<a href="https://ankanbhunia.github.io/PIDM/"><em style="color: #767872;">webpage</em></a>] <br>
              <strong>Ankan Bhunia</strong>,
              Salman Khan,
              Hisham Cholakkal,
              Rao Anwer,
        Jorma Laaksonen,
        Mubarak Shah,
              Fahad Khan,
       
              <br>
              <strong style="color: indianred;"><em>CVPR</em>, 2023</strong><br>

     
            </td>
          </tr>





          <tr>
            <td style="width:200px;height:100px; margin-left:20px;margin-top:15px;">
              <img id="figimage" class=shadow src="./src2/xmgan.png" height="90", width="120" style="margin-left:10px;">

            </td>              
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://link.springer.com/chapter/10.1007/978-3-031-43898-1_13">
                <papertitle>Cross-modulated Few-shot Image Generation for Colorectal Tissue Classification</papertitle>              </a>
                 - [<a href="https://link.springer.com/chapter/10.1007/978-3-031-43898-1_13"><em style="color: #767872;">paper</em></a>] / [<a href="https://github.com/VIROBO-15/XM-GAN"><em style="color: #767872;">code</em></a>] 
              <br>
              Amandeep Kumar, <strong>Ankan Bhunia</strong>, Sanath Narayan, Hisham Cholakkal, Rao Anwer, Jorma Laaksonen, Fahad Khan,
              <br>
              <strong style="color: indianred;"><em>MICCAI</em>, 2023</strong><br>
              <!-- -->


          <tr>


          <tr>
            <td style="width:200px;height:100px; margin-left:20px;margin-top:15px;">
              <img id="figimage" class=shadow src="./src2/doodles.png" height="90", width="120" style="margin-left:10px;">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2112.03258">
                <papertitle>DoodleFormer: Creative Sketch Drawing with Transformers</papertitle>
              </a>
              - [<a href="https://arxiv.org/abs/2112.03258"><em style="color: #767872;">paper</em></a>] / [<a href="https://github.com/ankanbhunia/doodleformer"><em style="color: #767872;">code</em></a>] / [<a href="https://ankanbhunia.github.io/doodleformer/"><em style="color: #767872;">webpage</em></a>] 
              <br>
              <strong>Ankan Bhunia</strong>,
              Salman Khan,
              Hisham Cholakkal,
              Rao Anwer,
              Fahad Khan,
        Jorma Laaksonen,
        Michael Felsberg,
              <br>
              <strong style="color: indianred;"><em>ECCV</em>, 2022</strong>

              
            </td>
          </tr>

          <tr>
            <td style="width:200px;height:100px; margin-left:20px;margin-top:15px;">
              <img id="figimage" class=shadow src="./src2/hwt.png" height="90", width="120" style="margin-left:10px;">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2104.03964">
                <papertitle>Handwriting Transformers</papertitle>
              </a>
              - [<a href="https://arxiv.org/abs/2104.03964"><em style="color: #767872;">paper</em></a>] / [<a href="https://github.com/ankanbhunia/Handwriting-Transformers"><em style="color: #767872;">code</em></a>] / [<a href="https://colab.research.google.com/github/ankanbhunia/Handwriting-Transformers/blob/main/demo.ipynb"><em style="color: #767872;">demo</em></a>] / [<a href="https://ankanbhunia.github.io/Handwriting-Transformers/"><em style="color: #767872;">webpage</em></a>] / [<a href="https://www.bloomberg.com/news/articles/2024-01-15/after-voice-clones-and-deepfake-videos-ai-can-now-mimic-handwriting?"><em style="color: #767872;">bloomberg article</em></a>] / [<a href="https://patents.google.com/patent/US11756244B1/en"><em style="color: #767872;">patent</em></a>] 



              <br>
              <strong>Ankan Bhunia</strong>,
              Salman Khan,
              Hisham Cholakkal,
              Rao Anwer,
              Fahad Khan,
        Mubarak Shah,
              <br>
              <strong style="color: indianred;"><em>ICCV</em>, 2021</strong>

              
            </td>
          </tr>

      
          <tr>
            <td style="width:200px;height:100px; margin-left:20px;margin-top:15px;">
                <img id="figimage" class=shadow src='./src2/im1.png' height="90", width="120" style="margin-left:10px;">  
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://openaccess.thecvf.com/content_CVPR_2019/html/Bhunia_Handwriting_Recognition_in_Low-Resource_Scripts_Using_Adversarial_Learning_CVPR_2019_paper.html">
                <papertitle>Handwriting Recognition in Low-resource Scripts using Adversarial Learning</papertitle>
              </a> - [<a href="http://openaccess.thecvf.com/content_CVPR_2019/html/Bhunia_Handwriting_Recognition_in_Low-Resource_Scripts_Using_Adversarial_Learning_CVPR_2019_paper.html"><em style="color: #767872;">paper</em></a>]
              <br>
        
              Ayan Kumar Bhunia,
              Abhirup Das,
        <strong>Ankan Bhunia</strong>,
              Sairaj Kishore,
              Partha Pratim Roy,
              <br>
              <strong style="color: indianred;"><em>CVPR</em>, 2019</strong>

            </td>
          </tr>
      
          <tr>
            <td style="width:200px;height:100px; margin-left:20px;margin-top:15px;">
                <img id="figimage" class=shadow src='./src2/im2.png' height="90", width="120" style="margin-left:10px;"> 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1810.11120">
                <papertitle>Improving Document Binarization via Adversarial Noise-Texture Augmentation</papertitle>
              </a> - [<a href="https://arxiv.org/abs/1810.11120"><em style="color: #767872;">paper</em></a>]
              <br>
        <strong>Ankan Bhunia</strong>,
              Ayan Kumar Bhunia,
              Aneeshan Sain,
              Partha Pratim Roy,
              <br>
              <strong style="color: indianred;"><em>ICIP</em>, 2019</strong>

            </td>
          </tr>     
    
              <tr>
            <td style="width:200px;height:100px; margin-left:20px;margin-top:15px;">
                <img id="figimage" class=shadow src='./src2/PR_logo.png' height="90", width="120" style="margin-left:10px;"> 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1811.01395">
                <papertitle>A Deep One-Shot Network for Query-based Logo Retrieval</papertitle>
              </a> - [<a href="https://arxiv.org/abs/1811.01395"><em style="color: #767872;">paper</em></a>]
              <br>
        
              Ayan Kumar Bhunia,
        <strong>Ankan Bhunia</strong>,
              Shuvozit Ghose,
              Partha Pratim Roy,
        Umapada Pal,
              <br>
              <strong style="color: indianred;"><em>Pattern Recognition</em>, 2019</strong>

            </td>
          </tr>   
    
    
      <tr>
            <td style="width:200px;height:100px; margin-left:20px;margin-top:15px;">
                <img id="figimage" class=shadow src='./src2/im4.png' height="90", width="120" style="margin-left:10px;"> 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1801.00470">
                <papertitle>Script identification in natural scene image and video frames using an attention based Convolutional-LSTM network</papertitle>
              </a> - [<a href="https://arxiv.org/abs/1801.00470"><em style="color: #767872;">paper</em></a>]
              <br>
        
              
        <strong>Ankan Bhunia</strong>,
              Aishik Konwer,
        Abir Bhowmik,
        Ayan Kumar Bhunia,
              Partha Pratim Roy,
      
              <br>
              <strong style="color: indianred;"><em>Pattern Recognition</em>, 2019</strong>

            </td>
          </tr>   
      
                    <tr>
            <td style="width:200px;height:100px; margin-left:20px;margin-top:15px;">
                <img id="figimage" class=shadow src='./src2/im5.png' height="90", width="120" style="margin-left:10px;"> 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1709.09348">
                <papertitle>Signature Verification Approach using Fusion of Hybrid Texture Features</papertitle>
              </a> - [<a href="https://arxiv.org/abs/1709.09348"><em style="color: #767872;">paper</em></a>]
              <br>
        
        <strong>Ankan Bhunia</strong>,
        Alireza Alaei,
              Partha Pratim Roy,

              <br>
              <strong style="color: indianred;"><em>Neural computing and Applications</em>, 2019</strong>
            </td>
          </tr>   
        <tr>
            <td style="width:200px;height:100px; margin-left:20px;margin-top:15px;">
                <img id="figimage" class=shadow src='./src2/im6.png' height="90", width="120" style="margin-left:10px;"> 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1801.07156">
                <papertitle>Word Level Font-to-Font Image Translation using Convolutional Recurrent Generative Adversarial Networks</papertitle>
              </a> - [<a href="https://arxiv.org/abs/1801.07156"><em style="color: #767872;">paper</em></a>]
              <br>
        <strong>Ankan Bhunia</strong>,
        Ayan Kumar Bhunia,
        Prithaj Banerjee,
              Aishik Konwer,
        Abir Bhowmik,
              Partha Pratim Roy,
        Umapada Pal,
              <br>
              <strong style="color: indianred;"><em>ICPR</em>, 2018</strong>

            </td>
          </tr>   
      
        <tr>
            <td style="width:200px;height:100px; margin-left:20px;margin-top:15px;">
                <img id="figimage" class=shadow src='./src2/im7.png' height="90", width="120" style="margin-left:10px;"> 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1801.07141">
                <papertitle>Staff line Removal using Generative Adversarial Networks</papertitle>
              </a> - [<a href="https://arxiv.org/abs/1801.07141"><em style="color: #767872;">paper</em></a>]
              <br>
        Aishik Konwer,
        Ayan Kumar Bhunia,
        Abir Bhowmik,
        <strong>Ankan Bhunia</strong>,
        Prithaj Banerjee,

              Partha Pratim Roy,
        Umapada Pal,
              <br>
              <strong style="color: indianred;"><em>ICPR</em>, 2018</strong>
            </td>
          </tr>   
      
              <tr>
            <td style="width:200px;height:100px; margin-left:20px;margin-top:15px;">
                <img id="figimage" class=shadow src='./src2/im8.png' height="90", width="120" style="margin-left:10px;"> 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1801.07211">
                <papertitle>Handwriting Trajectory Recovery using End-to-End Deep Encoder-Decoder Network</papertitle>
              </a> - [<a href="https://arxiv.org/abs/1801.07211"><em style="color: #767872;">paper</em></a>]
              <br>
        
        Ayan Kumar Bhunia,
        Abir Bhowmik,
        <strong>Ankan Bhunia</strong>,
        Aishik Konwer,
        Prithaj Banerjee,
              Partha Pratim Roy,
        Umapada Pal,
              <br>
              <strong style="color: indianred;"><em>ICPR</em>, 2018</strong>
            </td>
          </tr>   
      
            
      
        </tbody></table>

</div>


</li>
  <li id="content-research">
  <h3 class="research-heading">Topics: 3D Vision / Embodied Vision / Applications</h3>
<div class="card-container">
  

  <div class="card" style='width:100%;' >
    [<span class="conference-highlight">NeurIPS'25</span>] <strong style="color:black">&bull; <u>InteractiveAD</u></strong> - [<a href="https://groups.inf.ed.ac.uk/vico/research/interactiveAD/">webpage</a>]
    <p style='text-align:justify; font-size: 12px; color:gray'>
      Interactive agent-based AD framework for articulated 3D objects.<br><br>
    <img src="./src2/gifs/iad.gif" alt="this slowpoke moves"  width="100%"/>
    </p>
    </div>
  

  <div class="card" style='width:100%;' >
    [<span class="conference-highlight">CVPR'25</span>] <strong style="color:black">&bull; <u>Odd-One-Out</u></strong> - [<a href="https://arxiv.org/abs/2406.20099">Paper</a> / <a href="https://github.com/VICO-UoE/OddOneOutAD">GitHub</a> / <a href="https://github.com/VICO-UoE/OddOneOutAD">Dataset</a></a>] 
  <p style='text-align:justify; font-size: 12px; color:gray'>
    Detecting 'odd-looking' samples in multi-view multi-object scenes.<br><br>
  <img src="./src2/gifs/o3.gif" alt="this slowpoke moves"  width="100%"/>
  </p>
  </div>


  <div class="card" style='width:100%;' >
    [<span class="conference-highlight">CVPR'24</span>] <strong style="color:black">&bull; <u>Looking3D</u></strong> - [<a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Bhunia_Looking_3D_Anomaly_Detection_with_2D-3D_Alignment_CVPR_2024_paper.pdf">Paper</a> / <a href="https://github.com/VICO-UoE/Looking3D">GitHub</a> / <a href="https://groups.inf.ed.ac.uk/vico/research/Looking3D/">webpage</a> / <a href="https://uoe-my.sharepoint.com/:f:/g/personal/s2514643_ed_ac_uk/EjURAFBBbmxHvlMvDGrKvzEBOB29U3QShVRsqekp0rha_g?e=jenLk6">Dataset</a>] 
  <p style='text-align:justify; font-size: 12px; color:gray'>
    A new benchmark for conditional AD via 2D-3D alignment.<br><br>
  <img src="./src2/gifs/looking3d.gif" alt="this slowpoke moves"  width="100%"/>
  </p>
  </div>
</div>

<hr>

<h3 class="research-heading">Topics: Image Generative Models / Diffusion / GAN</h3>

<div class="card-container">

  <div class="card"  style='width:100%;' >
    [<span class="conference-highlight">CVPR'23</span>] <strong style="color:black">&bull; <u>PIDM</u></strong> - [<a href="https://arxiv.org/abs/2211.12500">Paper</a> / <a href="https://github.com/ankanbhunia/PIDM">GitHub</a> / <a href="https://ankanbhunia.github.io/PIDM/">webpage</a> / <a href="https://colab.research.google.com/github/ankanbhunia/PIDM/blob/main/PIDM_demo.ipynb"  style="color:red"><b>Demo</b></a>] 
<br> 
  <p  style='text-align:justify; font-size: 12px; color:gray'>
    Pose-guided person image synthesis via Diffusion models.
<br><br>
  <img src="./src2/gifs/pidm.gif" alt="this slowpoke moves"  width="100%"/><br>
  </p>
  </div>
 



  <div class="card"  style='width:100%;' >
    [<span class="conference-highlight">ICCV'23</span>] <strong style="color:black">&bull; <u>GMNR</u></strong> - [<a href="https://arxiv.org/pdf/2304.01172.pdf">Paper</a> / <a href="https://github.com/VIROBO-15/GMNR">GitHub</a>] 
<br>
  <p  style='text-align:justify; font-size: 12px; color:gray'> A novel 3D-aware generative model based on multi-plane represenation.
<br><br>
  <img src="./src2/gifs/gmnr.gif" alt="this slowpoke moves"  width="100%"/><br> 
  </p>
  </div>



  <div class="card"  style='width:100%;' >
    [<span class="conference-highlight">ECCV'22</span>] <strong style="color:black">&bull; <u>Doodleformer</u></strong> - [<a href="https://arxiv.org/pdf/2112.03258">Paper</a> / <a href="https://github.com/ankanbhunia/doodleformer">GitHub</a> / <a href="https://ankanbhunia.github.io/doodleformer/">webpage</a>] 
<br>
  <p style='text-align:justify; font-size: 12px; color:gray'> A new coarse-to-fine framework for creative sketch generation problem.
<br><br>
  <img src="./src2/gifs/doodleformer.jpeg" alt="this slowpoke moves"  width="100%"/><br>
  </p>
  </div>
 



  <div class="card"  style='width:100%;' >
    [<span class="conference-highlight">ICCV'21</span>] <strong style="color:black">&bull; <u>HWT</u></strong> - [<a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Bhunia_Handwriting_Transformers_ICCV_2021_paper.pdf">Paper</a> / <a href="https://github.com/ankanbhunia/Handwriting-Transformers">GitHub</a> / <a href="https://ankanbhunia.github.io/Handwriting-Transformers/">webpage</a> / <a href="https://colab.research.google.com/github/ankanbhunia/Handwriting-Transformers/blob/main/demo.ipynb" style="color:red"><b>Demo</b></a> / <a href="https://huggingface.co/spaces/ankankbhunia/HWT">Huggingface-demo</a>] 
<br>
  <p style='text-align:justify; font-size: 12px; color:gray'> Handwriting Synthesis - Generate text in anyone's handwriting. 
<br><br>
  <img src="./src2/gifs/hwt.gif" alt="this slowpoke moves"  width="100%"/><br>
  </p>
</div>
 



  <li id="content-patents">
    <div class="card-container">
      <div class="card" style='width:100%; margin: auto;'>
        <strong style="color:black">&bull; <u>[09/2023] System and method for handwriting generation</u></strong> - [<a href="https://patents.google.com/patent/US11756244B1/en"><em style="color: #767872;">link</em></a>]
        <br><br>
        <img src="./patents/hwt.png" alt="this slowpoke moves"  width="100%"/><br>

      </div>
      <div class="card" style='width:100%; margin: auto;'>
        <strong style="color:black">&bull; <u>[09/2024] System and method of cross-modulated dense local fusion for few-shot image generation</u></strong> - [<a href="https://patents.google.com/patent/US12100082B2/en"><em style="color: #767872;">link</em></a>]
        <br><br>
        <img src="./patents/xmgan.png" alt="this slowpoke moves"  width="100%"/><br>

      </div>
    </div>
  </li>

  
  <li id="content-contact" style='text-align: center; font-family:courier;'>
<iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d1556.1956136720185!2d-3.187865156749468!3d55.9450301321123!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x4887c78381d04457%3A0xd072ab38eb50c7a4!2sSchool%20of%20Informatics!5e0!3m2!1sen!2suk!4v1684098165835!5m2!1sen!2suk" width="300" height="225" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe><br><br>

    The Bayes Centre, Edinburgh EH8 9BT <br>
    Email: ankankumarbhunia [at] gmail.com / <br>
    ankan.bhunia [at] ed.ac.uk<br>


  </li>

</ul>

      </td>
    </tr>
  </tbody></table>
<hr>
<footer id="colophon" class="site-footer" role="contentinfo" style="margin-left: -30px;">
  <div class="social-wrapper">
    <ul>
      <li>
        <a href="https://twitter.com/ankanbh" target="_blank">
          <img src="https://raw.githubusercontent.com/ankanbhunia/ankanbhunia.github.io/master/src2/icons/twitter.png" alt="Twitter Logo" class="twitter-icon"></a>
      </li>
      <li>
        <a href="https://wa.me/919038858890" target="_blank">
          <img src="https://raw.githubusercontent.com/ankanbhunia/ankanbhunia.github.io/master/src2/icons/wa.png" alt="Instagram Logo" class="instagram-icon"></a>
      </li>
            <li>
        <a href="https://www.linkedin.com/in/ankan-kumar-bhunia/" target="_blank">
          <img src="https://raw.githubusercontent.com/ankanbhunia/ankanbhunia.github.io/master/src2/icons/linkedin.png" alt="Instagram Logo" class="instagram-icon"></a>
      </li>

      <li>
        <a href="https://www.youtube.com/channel/UC2G-oDOz9FTJN-b839_mZtA" target="_blank">
          <img src="https://raw.githubusercontent.com/ankanbhunia/ankanbhunia.github.io/master/src2/icons/youtube.png" alt="Youtube Logo" class="youtube-icon"></a>
      </li>
      <li>
        <a href="https://github.com/ankanbhunia" target="_blank">
          <img src="https://raw.githubusercontent.com/ankanbhunia/ankanbhunia.github.io/master/src2/icons/github.png" alt="Foursquare Logo" class="foursquare-icon"></a>
      </li>
            <li>
        <a href="http://scholar.google.com/citations?user=2leAc3AAAAAJ&hl=en" target="_blank">
          <img src="https://raw.githubusercontent.com/ankanbhunia/ankanbhunia.github.io/master/src2/icons/gsc.png" alt="Foursquare Logo" class="foursquare-icon"></a>
      </li>
            <li>
        <a href="https://dblp.org/pid/206/7200" target="_blank">
          <img src="https://raw.githubusercontent.com/ankanbhunia/ankanbhunia.github.io/master/src2/icons/dblp.png" alt="Foursquare Logo" class="foursquare-icon"></a>
      </li>
    </ul>
  </div>

</footer>
<!-- #colophon -->

</div>
</div>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>


<script>
$(function () {
  var $contentlis = $('.tabs-content li'),
      $tabslis = $('.tabs li');

  // Function to activate a tab
  function activateTab(tabId) {
    $tabslis.removeClass('active-tab');
    $contentlis.hide();

    var $targetTab = $('#tab-' + tabId);
    var $targetContent = $('#content-' + tabId);

    if ($targetTab.length && $targetContent.length) {
      $targetTab.addClass('active-tab');
      $targetContent.show();
    } else {
      // Default to Publications if tabId is not found or invalid
      $('#tab-publications').addClass('active-tab');
      $('#content-publications').show();
    }
  }

  // Handle initial page load based on URL
  var hash = window.location.hash;
  var defaultTab = 'publications'; // Default tab if no specific path is found

  // Extract tab name from hash (e.g., #research, #patents, #contact)
  if (hash && hash.length > 1) {
    var tabName = hash.substring(1).toLowerCase();
    // Only activate if the tab exists
    if ($('#tab-' + tabName).length && $('#content-' + tabName).length) {
      defaultTab = tabName;
    }
  }

  activateTab(defaultTab);

  // Handle tab clicks
  $('.tabs').on('click', 'li', function (e) {
    var $current = $(e.currentTarget);
    var tabId = $current.attr('id').replace('tab-', '');
    activateTab(tabId);
    window.location.hash = '#' + tabId; // Update URL hash on tab click
  });

  // Handle browser back/forward navigation (hashchange)
  window.addEventListener('hashchange', function () {
    var hash = window.location.hash;
    if (hash && hash.length > 1) {
      var tabName = hash.substring(1).toLowerCase();
      if ($('#tab-' + tabName).length && $('#content-' + tabName).length) {
        activateTab(tabName);
      }
    }
  });
});

</script>
<script>
    function changeImage() {
        document.getElementById("dmimage").src = "im2.png";
    }

    function restoreImage() {
        document.getElementById("dmimage").src = "im1.png";
    }
</script>
</body>
